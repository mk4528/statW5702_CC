---
title: "CC: Introduction to XAI (Explainable Artificial Intelligence) in R"
output:
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

### 1. Motivation
Unlike linear models and decision trees, machine learning models are often described as black box models due to their complexity. It is difficult to describe the relationship between independent and dependent variables so that humans can intuitively understand. For this reason, machine learning models tend to be avoided in cases where the goal is to explain the mechanism of event occurrence, or where the causes of model’s prediction must be explained to convince those who will be affected by the decision. In other words, machine learning is mainly used for tasks where prediction itself is important. However, simple interpretable models have a limit to the events that can be described. So, to utilize machine learning models, investigations and researches on methods to explain the model structure in a format easy for humans to understand have progressed. In addition, The General Data Protection Regulation in EU, the strictest privacy and security law in the world, puts a premium on transparent AI. Therefore, the interpretability of machine learning models is becoming and required by society.

### 2. Own Evaluation
I explained famous XAI methods in the iml package and the way to implement in R. While this topic is quite important in the current data science projects, it was tough to understand the logic, explain briefly, and implement simply by an appropriate package. Also, the explanation needed the constructions of black box model. I learned a whole of the way to interpret models, including the way to make NN model, and the importance of interpretability and explanation for our created models. Next time, I will learn also less famous methods, implement them for other models to confirm the possibility of usage to them, and try to find the best combination of the XAI methods to some kinds of models with less cost because I learned that there are some methods which is easy to implement for some models, such as tree models, but not for others.

### 3. Introduction
XAI (Explainable Artificial Intelligence), as the term implies, refers to machine learning models in which the processes leading to predicted or estimated results can be explained by humans, or to technologies and research fields related to these models. I will introduce the methods to explain black box models as one of the technologies. Many methods are now introduced but I will focus on ones we can implement in R using the iml package.

Specifically, I will explain the way to interpret entire model (Permutation Feature Importance), the relation between dependent and independent variables (PDP, ICE plot, ALE plot, and Friedman’s H-statistic), local effect of independent variables (shapley value) and the way to implement them in R in the following sections. The iml package has the methods to plot them.

At first, I created the neural network model (NN model) as a black box model. To introduce XAI simply, I used ames dataset in the openintro package and selected some of the numeric variables as independent variables.